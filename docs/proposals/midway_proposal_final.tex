\documentclass[10pt,twocolumn,a4paper]{article}

% ---- Packages ----
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{lmodern}
\usepackage[top=1.8cm,bottom=1.8cm,left=1.5cm,right=1.5cm]{geometry}
\usepackage{microtype}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{booktabs}
\usepackage{enumitem}
\usepackage{titlesec}
\usepackage{xcolor}
\usepackage{hyperref}
\usepackage{tabularx}
\usepackage{array}
\usepackage{colortbl}
\usepackage{graphicx}
\usepackage{fancyhdr}
\usepackage[numbers,sort&compress]{natbib}
\usepackage{url}
\usepackage{caption}
\usepackage{tikz}
\usepackage{calc}
\usepackage{needspace}
\usetikzlibrary{positioning,calc}

% ---- Colors ----
\definecolor{umdark}{HTML}{001C3D}
\definecolor{umorange}{HTML}{E84E10}
\definecolor{umlight}{HTML}{4A90C4}
\definecolor{umgray}{HTML}{6B7280}
\definecolor{ganttblue}{HTML}{2563EB}
\definecolor{ganttred}{HTML}{DC2626}
\definecolor{ganttgreen}{HTML}{059669}
\definecolor{ganttamber}{HTML}{D97706}
\definecolor{ganttpurple}{HTML}{7C3AED}
\definecolor{ganttgray}{HTML}{9CA3AF}

% ---- Formatting ----
\hypersetup{colorlinks=true,linkcolor=umdark,citecolor=umlight,urlcolor=umlight}
\setlength{\columnsep}{0.6cm}
\setlength{\parskip}{2pt plus 1pt}
\setlength{\parindent}{0.8em}

% Compact sections
\titleformat{\section}{\normalfont\bfseries\normalsize\color{umdark}}{\thesection.}{0.4em}{}[\vspace{-2pt}\color{umorange}\rule{\columnwidth}{0.6pt}]
\titleformat{\subsection}{\normalfont\bfseries\small}{\thesubsection}{0.4em}{}
\titlespacing*{\section}{0pt}{8pt plus 2pt}{4pt plus 1pt}
\titlespacing*{\subsection}{0pt}{5pt plus 2pt}{2pt plus 1pt}

% Compact lists
\setlist{nosep,leftmargin=1.2em}
\captionsetup{font=small,labelfont=bf,skip=4pt}

% ---- Header/Footer ----
\pagestyle{fancy}
\fancyhf{}
\renewcommand{\headrulewidth}{0pt}
\fancyfoot[C]{\small\thepage}

% ============================================================
% Title
% ============================================================
\title{\vspace{-1.2cm}\textbf{Does the Source of Carrier Image Affect\\
Steganographic Detectability?}\\[4pt]
\large Midway Project Proposal\\[6pt]
\normalsize\textit{Project 2.2, Department of Advanced Computing Sciences}}
\author{Abdul Moiz Akbar \quad Malo Coquin \quad Daria Gjonbalaj \quad Nico Müller-Späth\\[2pt]
Jimena Narvaez del Cid \quad David Wicker \quad Nikolas Zouros\\[2pt]
\small Maastricht University \quad$\cdot$\quad February 2026}
\date{}

\begin{document}
\maketitle
\thispagestyle{fancy}
\vspace{-0.6cm}

% ============================================================
\section{Motivation and Problem Statement}
% ============================================================

Image steganography is an important topic in online security and privacy, with both beneficial and adversarial uses~\cite{petitcolas1999,cheddad2010,provos2003f5}. In practice, detectability depends not only on the embedding method but also on the underlying statistics of the carrier image~\cite{hussain2018,fridrich2012srm}. Steganalysis works by detecting subtle distributional perturbations in pixel values, residuals, and frequency coefficients after embedding. This is exactly why carrier selection matters: two carriers with identical payload and identical embedding can produce different detectability outcomes.

Most existing steganalysis pipelines were developed and benchmarked on real camera photographs, where sensor noise and compression traces are relatively well characterized. This assumption is increasingly fragile. Photorealistic synthetic images from modern generators such as Stable Diffusion and StyleGAN3 are now widespread~\cite{rombach2022sd,karras2021sg3}, and they are produced by different mechanisms than camera pipelines. Prior synthetic-image forensics shows that generated images can contain distinct statistical traces~\cite{wang2020cnn,corvi2023diffusion}, which may directly influence steganographic detectability.

The core question is therefore: \textbf{do steganalysis detectors validated on photographs remain equally effective on ML-generated carriers under identical embedding settings?} This matters for three reasons:
\begin{itemize}
\item \textbf{Security:} if ML-generated carriers are harder to detect, an attacker may evade existing detectors by changing carrier source only.
\item \textbf{Scientific:} the interaction between generative-model distributions and embedding perturbations remains underexplored.
\item \textbf{Practical:} as AI-generated images become common in communication channels, the steganographic attack surface expands.
\end{itemize}

The problem statement for this project is to quantify whether \emph{carrier origin alone} (real vs.\ ML-generated) causes measurable detection differences when embedding, payload, and detector settings are fixed. If origin effects are large, detector calibration and risk assumptions built on photo-only datasets may not transfer to mixed real/synthetic traffic.

The closest precedent is De et al.~\cite{de2022ai}, who demonstrate AI-generated images for steganographic secret sharing, but without a controlled real-vs-ML carrier comparison using standardized LSB/DCT pipelines and classical steganalysis endpoints. In other words, feasibility of secret sharing on generated images has been shown, but comparative detectability under matched conditions is still unclear.

This study addresses that gap with a controlled $2\!\times\!2\!\times\!3\!\times\!2$ design over 1{,}000 images (500 real, 500 ML-generated), two embedding methods, three payload levels, and two primary detectors. By keeping embedding, payload, and detector settings fixed while varying carrier origin, we isolate whether origin itself is a meaningful source of detection-performance differences. Results will guide benchmarking and steganalysis policy in mixed real/synthetic environments.

% ============================================================
\section{Research Questions}
% ============================================================

\begin{description}[font=\normalfont\bfseries,leftmargin=1em,style=nextline]

\item[RQ1 (Carrier Origin)] Is there any effect of carrier-image origin (real vs.\ ML-generated) on detectability of hidden data?
\\\textcolor{umorange}{\textit{Verification:} Compare real vs.\ ML AUC with RS and SRM+FLD at identical settings; report significance and effect size.}

\item[RQ2 (Payload)] Does increasing payload size widen the detectability gap between real and ML-generated carriers?
\\\textcolor{umorange}{\textit{Verification:} Measure AUC gap across Low/Medium/High payloads and test trend plus carrier$\times$payload interaction.}

\item[RQ3 (Encryption)] Does encrypting payload before embedding make steganography harder or easier to detect, and does origin change this effect?
\\\textcolor{umorange}{\textit{Verification:} Compare plain vs.\ AES-256-CBC AUC by carrier and method; test significance of the difference.}

\item[RQ4 (Embedding Method)] Do different embedding methods (spatial LSB vs.\ frequency-domain DCT) interact differently with carrier origin in terms of detectability?
\\\textcolor{umorange}{\textit{Verification:} Run a two-way ANOVA on AUC for carrier origin and embedding method; inspect interaction term.}

\item[RQ5 (Image Quality)] Is image quality affected by embedding method and payload size?
\\\textcolor{umorange}{\textit{Verification:} Compare PSNR/SSIM/FSIM across conditions and check against quality targets (PSNR $>\!40$\,dB, SSIM $>\!0.95$).}

\end{description}

% ============================================================
\Needspace{8\baselineskip}
\section{Chosen Approaches}
% ============================================================

\subsection{Datasets}

\textbf{Real images (500 total).} We draw from three established photographic datasets chosen for their diversity and research accessibility: \textbf{RAISE}~\cite{raise2015} contributes 250 RAW-demosaiced DSLR images spanning outdoor, indoor, portrait, and macro scenes; \textbf{COCO}~\cite{coco2014} contributes 150 images from its validation split; and \textbf{Flickr30k}~\cite{flickr30k2014} contributes 100 images. All images are normalized to 512$\times$512\,px, RGB, 8-bit, lossless PNG. RAISE is preferred as the primary source because its RAW format preserves camera sensor noise structure, which is the natural image statistics that steganalysis exploits.

\textbf{ML-generated images (500 total).} We generate two matched sets of 250 images each using \textbf{Stable Diffusion v2.1}~\cite{rombach2022sd} (via the \texttt{diffusers} library on Apple MPS) and \textbf{StyleGAN3}~\cite{karras2021sg3} (official NVIDIA PyTorch implementation). Prompts for SD are derived directly from COCO/Flickr30k captions to achieve semantic alignment with real images. A BRISQUE~$\leq\!50$ quality gate rejects perceptually degraded outputs.

These two generative paradigms (latent diffusion and GAN-based synthesis) represent the dominant architectures in open-source image generation and are expected to impose distinct statistical signatures on the output.

\subsection{Embedding Methods}

We implement two canonical steganographic methods spanning the two principal domains:

\textbf{LSB substitution (spatial domain)} replaces the $k$ least significant bits of each pixel channel value with pseudorandom message bits, using a PRNG-keyed pixel selection mask. We test $k\!=\!1$ (Low, Medium payload) and $k\!=\!2$ (High payload). Payloads are optionally pre-encrypted with AES-256-CBC before embedding, addressing RQ3.

\textbf{DCT-based embedding (frequency domain)} partitions each image channel into non-overlapping 8$\times$8 blocks, computes the 2D DCT, and embeds bits into mid-frequency coefficients (zigzag positions 10--54) via \textbf{Quantization Index Modulation} (QIM)~\cite{chen_wornell2001}:
\[
C'_i = \Delta\cdot\operatorname{round}\!\left(\tfrac{C_i}{\Delta}\right) \pm \tfrac{\Delta}{4},
\]
where the sign encodes the message bit. DCT embedding is chosen alongside LSB to test whether frequency-domain methods are more sensitive to carrier origin (RQ4), since DCT coefficients reflect the generative model's learned spectral distribution directly.

\subsection{Steganalysis Detectors}

Our detector selection is deliberately scoped to \emph{classical signal processing and statistics}, consistent with this project's cryptography/steganography focus:

\begin{table}[h]
\centering
\caption{Steganalysis detector comparison.}
\label{tab:detectors}
\scriptsize
\setlength{\tabcolsep}{4pt}
\begin{tabular}{@{}lllll@{}}
\toprule
\textbf{Detector} & \textbf{Type} & \textbf{Training} & \textbf{Domain} & \textbf{Time} \\
\midrule
RS Analysis~\cite{fridrich2001lsb} & Statistical & None & Any & ${\sim}$2\,s/img \\
$\chi^2$ attack~\cite{westfeld1999chi} & Statistical & None & LSB & $<$1\,s/img \\
SRM+FLD~\cite{fridrich2012srm} & Classical ML & Labeled & LSB+DCT & $<$30\,min \\
\bottomrule
\end{tabular}
\end{table}

\textbf{RS Analysis}~\cite{fridrich2001lsb} partitions an image into pixel groups and classifies each as Regular or Singular by a smoothness function; LSB embedding shifts the R/S ratio predictably, yielding an analytical estimate $\hat{p}$ of embedding rate. Since it requires no training, any detection difference between real and ML-generated carriers is attributable solely to carrier statistics and not to classifier bias.

\textbf{SRM + Fisher Linear Discriminant (FLD) ensemble}~\cite{fridrich2012srm} extracts ${\sim}35{,}000$-dimensional co-occurrence feature vectors from high-pass residuals, then classifies with an ensemble of FLD classifiers. It handles DCT embedding better than the training-free methods and its hand-crafted features are hypothesised to generalise better across the real/ML boundary than learned neural network representations. Implemented with \texttt{scikit-learn}'s \texttt{SGDClassifier}; 3-fold stratified CV.

The $\chi^2$ attack~\cite{westfeld1999chi} is applied as a supplementary check on LSB results.

\subsection{Validation}

\textbf{Detection:} ROC-AUC (primary, threshold-independent); accuracy at Youden's~$J$; EER; FPR at 5\%~FNR.
\textbf{Image quality:} PSNR~($>\!40$\,dB target), SSIM~($>\!0.95$ target), FSIM.
\textbf{Statistics:} Two-way ANOVA (carrier $\times$ method) on AUC with payload as covariate; Wilcoxon signed-rank for pairwise comparisons; Cohen's~$d$ effect sizes; Bonferroni correction ($\alpha_{\text{adj}}\!=\!0.05/6\!\approx\!0.0083$) across six hypotheses.

% ============================================================
\section{Experiments}
% ============================================================

Each research question maps to exactly one experiment; every experiment links back to its RQ.

\textbf{Exp.\,1 (RQ1: Carrier Origin).} Apply RS Analysis and SRM+FLD to all 1{,}000 images across payload levels and methods. Compute AUC per carrier type and compare real vs.\ ML-generated performance with Wilcoxon signed-rank and Cohen's~$d$ (Bonferroni-corrected).

\textbf{Exp.\,2 (RQ2: Payload).} From Exp.\,1 results, plot AUC vs.\ payload level (Low/Medium/High) separately for real and ML-generated carriers, with separate curves per embedding method. Test whether the real--ML AUC gap increases monotonically using Spearman's $\rho$, and test carrier $\times$ payload interaction.

\textbf{Exp.\,3 (RQ3: Encryption).} For each carrier type and embedding method, compare AUC between plain-payload and AES-256-CBC-encrypted-payload conditions. Test whether encryption changes detectability and whether the effect differs by carrier origin.

\textbf{Exp.\,4 (RQ4: Embedding Method).} Run a $2\!\times\!2$ two-way ANOVA with factors carrier origin (real/ML) and embedding method (LSB/DCT) on SRM AUC scores. A significant interaction indicates method-dependent detectability differences across carrier origin.

\textbf{Exp.\,5 (RQ5: Image Quality).} Compute PSNR, SSIM, and FSIM for each stego condition relative to its cover image. Compare quality metrics across payload levels and embedding methods, and confirm whether quality remains within target ranges.

% ============================================================
\Needspace{8\baselineskip}
\section{Prototype}
% ============================================================

\textbf{Vertical prototype (algorithm depth):} We validate the core components separately before scaling: LSB embedding/extraction, DCT-QIM embedding, RS Analysis, and SRM feature extraction/classification on a small test subset.

\textbf{Horizontal prototype (integration breadth):} We then run an integrated pipeline on a mixed 50-image subset (25~real~+~25~ML) at medium payload to validate interfaces and outputs before executing the full 1{,}000-image study.

% ============================================================
\section{Related Work}
% ============================================================

\subsection{Classical Embedding and Detection Foundations}
Image steganography has predominantly focused on embedding secret data into photographic carriers using spatial- and frequency-domain techniques~\cite{petitcolas1999,cheddad2010,hussain2018}. Canonical examples include LSB substitution, which perturbs pixel intensities directly, and DCT-based Quantization Index Modulation (QIM), which embeds information in transform coefficients~\cite{chen_wornell2001}. We adopt these established post-hoc embedding strategies rather than introducing a new embedding algorithm, to preserve comparability with prior steganalysis literature and isolate the effect of carrier origin.

On the detection side, RS analysis and the $\chi^2$ attack provide analytical baselines for LSB-like embedding~\cite{fridrich2001lsb,westfeld1999chi}. Rich-model approaches remain strong classical baselines: Fridrich and Kodovsk\'{y}~\cite{fridrich2012srm} introduced SRM features that capture high-dimensional residual co-occurrences linked to embedding artifacts.

\subsection{Generative and Coverless Steganography}
Recent generative steganography methods use GAN- or diffusion-based models to generate stego-images directly from secret messages~\cite{hu2023,liu2024}. Related coverless approaches encode information by selecting or generating content rather than modifying a fixed image~\cite{duan2020}. Our setup differs in a key way: ML-generated images are treated as \emph{passive carriers}, and standardized post-hoc embedding (LSB and DCT) is applied afterward. This separation between generation and embedding lets us test carrier-origin effects under matched embedding conditions.

\subsection{AI-Generated Carriers and Closest Prior Work}
The closest related study is De et al.~\cite{de2022ai}, which demonstrates AI-generated photorealistic images for steganographic secret sharing. However, it does not perform a controlled real-versus-ML comparison under identical embedding pipelines, nor does it evaluate detectability using classical steganalysis endpoints such as ROC-AUC. Our factorial design (carrier origin $\times$ embedding method $\times$ payload size $\times$ encryption) makes steganalysis detectability the primary outcome.

\subsection{Cross-Domain and Synthetic-Image Forensics}
Cross-domain steganalysis has typically examined distribution shifts between camera sources~\cite{fridrich2012srm}. The real-versus-synthetic shift is broader, because the full image-generation process changes when moving from camera capture to GAN or diffusion synthesis. Synthetic-image forensics reports distinct statistical traces in generated images~\cite{wang2020cnn,corvi2023diffusion}, supporting our hypothesis that carrier origin can affect steganographic detectability.

\subsection{Classical vs.\ Deep Steganalysis}
Recent deep-learning steganalysis methods can achieve strong benchmark accuracy~\cite{luo2024survey}, but often with higher computational requirements and reduced interpretability. We therefore prioritize SRM+FLD and RS analysis to maintain interpretability and CPU feasibility, in line with the cryptography-focused scope of this project. Overall, prior work has studied embedding techniques, steganalysis models, generative steganography, and synthetic-image detection largely in isolation; our contribution is a controlled evaluation of how carrier origin influences detectability.

% ============================================================
\section{Relation to Curriculum}
% ============================================================

This project connects directly to \textbf{Computer Security} (AES-256-CBC and adversarial threat modeling), \textbf{AI and Machine Learning} (SRM+FLD feature-based classification and cross-domain evaluation), \textbf{Software Engineering and Architectures} (modular, testable pipeline design), and \textbf{Statistics} (ANOVA, non-parametric testing, effect sizes, and confidence intervals for rigorous comparison).

% ============================================================
\section{Planning}
% ============================================================

The project is divided into two phases aligned with the Semester~2 academic calendar. Detailed Gantt charts are provided in Appendix~\ref{app:gantt}.

\textbf{Phase~2: Implementation} (Period~5, 30~Mar--15~May 2026, 7~weeks) covers three parallel workstreams: dataset construction and ML image generation (Wk~1--2), steganography pipeline implementation including LSB, DCT, and AES-256 encryption (Wk~2--3), and detection, analysis, and writing (Wk~3--7).

\textbf{Phase~3: Completion} (Project Period, 25~May--12~Jun 2026, 3~weeks) covers completing any remaining implementation, verifying and rerunning experiments, and finalising all deliverables (presentation slides, poster, and paper).

% ============================================================
\section{Minimal Passing Requirements}
% ============================================================

In terms of approaches, the minimum is one encryption algorithm and two embedding methods: one in the spatial domain and one in the frequency domain.

From the five research questions, at minimum RQ3 (encryption) and RQ4 (embedding-method interaction) must be answered.

% ============================================================
\clearpage
\renewcommand{\refname}{References}
% ============================================================

\begin{thebibliography}{25}
\small

\bibitem{petitcolas1999}
F.~A.~P.~Petitcolas, R.~J.~Anderson, and M.~G.~Kuhn,
``Information hiding: a survey,''
\textit{Proc.\ IEEE}, vol.~87, no.~7, pp.~1062--1078, 1999.

\bibitem{cheddad2010}
A.~Cheddad, J.~Condell, K.~Curran, and P.~McKevitt,
``Digital image steganography: Survey and analysis of current methods,''
\textit{Signal Process.}, vol.~90, no.~3, pp.~727--752, 2010.

\bibitem{hussain2018}
M.~Hussain, A.~W.~A.~Wahab, Y.~I.~B.~Idris, A.~T.~S.~Ho, and K.~H.~Jung,
``Image steganography in spatial domain: A survey,''
\textit{Signal Process.: Image Commun.}, vol.~65, pp.~46--66, 2018.

\bibitem{fridrich2012srm}
J.~Fridrich and J.~Kodovsk\'{y},
``Rich models for steganalysis of digital images,''
\textit{IEEE Trans.\ Inf.\ Forensics Security}, vol.~7, no.~3, pp.~868--882, 2012.

\bibitem{rombach2022sd}
R.~Rombach, A.~Blattmann, D.~Lorenz, P.~Esser, and B.~Ommer,
``High-resolution image synthesis with latent diffusion models,''
in \textit{Proc.\ IEEE CVPR}, pp.~10684--10695, 2022.

\bibitem{karras2021sg3}
T.~Karras, M.~Laine, M.~Aittala, J.~Hellsten, J.~Lehtinen, and T.~Aila,
``Alias-free generative adversarial networks,''
in \textit{Proc.\ NeurIPS}, vol.~34, pp.~852--863, 2021.

\bibitem{de2022ai}
A.~De, W.~Kinzel, and I.~Kanter,
``Steganographic secret sharing via AI-generated photorealistic images,''
\textit{EURASIP J.\ Wireless Commun.\ Netw.}, art.~108, 2022.

\bibitem{fridrich2001lsb}
J.~Fridrich, M.~Goljan, and R.~Du,
``Detecting LSB steganography in color and grayscale images,''
\textit{IEEE Multimedia}, vol.~8, no.~4, pp.~22--28, 2001.

\bibitem{westfeld1999chi}
A.~Westfeld and A.~Pfitzmann,
``Attacks on steganographic systems,''
in \textit{Proc.\ 3rd Int.\ Workshop Information Hiding}, LNCS 1768, pp.~61--76, 1999.

\bibitem{provos2003f5}
N.~Provos and P.~Honeyman,
``Hide and seek: An introduction to steganography,''
\textit{IEEE Security Privacy}, vol.~1, no.~3, pp.~32--44, 2003.

\bibitem{chen_wornell2001}
B.~Chen and G.~W.~Wornell,
``Quantization index modulation: A class of provably good methods for digital watermarking and information embedding,''
\textit{IEEE Trans.\ Inf.\ Theory}, vol.~47, no.~4, pp.~1423--1443, 2001.

\bibitem{wang2020cnn}
S.~Y.~Wang, O.~Wang, R.~Zhang, A.~Owens, and A.~A.~Efros,
``CNN-generated images are surprisingly easy to spot\ldots for now,''
in \textit{Proc.\ IEEE CVPR}, pp.~8695--8704, 2020.

\bibitem{corvi2023diffusion}
R.~Corvi, D.~Cozzolino, G.~Zingarini, G.~Poggi, K.~Nagano, and L.~Verdoliva,
``On the detection of synthetic images generated by diffusion models,''
in \textit{Proc.\ IEEE ICASSP}, pp.~1--5, 2023.

\bibitem{raise2015}
D.-T.~Dang-Nguyen, C.~Pasquini, V.~Conotter, and G.~Boato,
``RAISE: A raw images dataset for digital image forensics,''
in \textit{Proc.\ ACM MMSys}, pp.~219--224, 2015.

\bibitem{coco2014}
T.-Y.~Lin et al.,
``Microsoft COCO: Common objects in context,''
in \textit{Proc.\ ECCV}, LNCS 8693, pp.~740--755, 2014.

\bibitem{flickr30k2014}
P.~Young, A.~Lai, M.~Hodosh, and J.~Hockenmaier,
``From image descriptions to visual denotations,''
\textit{Trans.\ Assoc.\ Comput.\ Linguist.}, vol.~2, pp.~67--78, 2014.

\bibitem{luo2024survey}
Y.~Luo et al.,
``Deep learning for steganalysis of diverse data types: A review,''
\textit{Neurocomputing}, Elsevier, 2024.

\bibitem{holub2014}
V.~Holub, J.~Fridrich, and T.~Denemark,
``Universal distortion function for steganography in an arbitrary domain,''
\textit{EURASIP J.\ Inf.\ Security}, art.~1, 2014.

\bibitem{hu2023}
P.~Hu et al.,
``A coverless image steganography based on generative adversarial networks,''
\textit{Electronics}, vol.~12, no.~5, art.~1253, 2023.

\bibitem{liu2024}
X.~Liu et al.,
``Message-driven generative steganography using GAN,''
\textit{IEEE Trans.\ Dependable Secure Comput.}, 2024.

\bibitem{duan2020}
X.~Duan, D.~Jia, B.~Li, D.~Guo, E.~Zhang, and C.~Qin,
``Coverless steganography based on generative adversarial network,''
\textit{EURASIP J.\ Image Video Process.}, art.~46, 2020.

\end{thebibliography}

% ============================================================
% APPENDIX — full-width Gantt charts (table-based)
% ============================================================
\clearpage
\onecolumn
\appendix

\section{Project Gantt Charts}
\label{app:gantt}

% ------------------------------------------------------------------
% Phase 2: Implementation (Period 5, 30 Mar -- 15 May 2026, 7 weeks)
% ------------------------------------------------------------------

\noindent\textbf{\large Phase 2: Implementation} \hfill
\textit{Period~5: 30~March\,--\,15~May 2026 (7~weeks)}

\vspace{6pt}

{%
\setlength{\tabcolsep}{2pt}
\renewcommand{\arraystretch}{1.2}
\footnotesize
\noindent\begin{tabularx}{\textwidth}{
  |>{\centering\arraybackslash}p{0.8cm}
  |>{\raggedright\arraybackslash}p{4.6cm}
  |>{\centering\arraybackslash}p{1.2cm}
  |>{\centering\arraybackslash}p{1.2cm}
  |>{\centering\arraybackslash}p{0.8cm}
  |*{7}{>{\centering\arraybackslash}X|}
}
\hline
\rowcolor{umdark!10}
\textbf{WBS} & \textbf{Task} & \textbf{Start} & \textbf{End} & \textbf{Days} &
\textbf{Wk\,1} & \textbf{Wk\,2} & \textbf{Wk\,3} & \textbf{Wk\,4} &
\textbf{Wk\,5} & \textbf{Wk\,6} & \textbf{Wk\,7} \\
\hline

% --- Section 1: Data ---
\rowcolor{ganttblue!8}
\textbf{1} & \textbf{Data Construction} & & & & & & & & & & \\
\hline
1.1 & Dataset collection (RAISE/COCO/Flickr30k) & 30.03 & 10.04 & 10 &
  \cellcolor{ganttblue!50} & \cellcolor{ganttblue!50} & & & & & \\
\hline
1.2 & ML image generation (SD~v2.1 + StyleGAN3) & 30.03 & 10.04 & 10 &
  \cellcolor{ganttblue!50} & \cellcolor{ganttblue!50} & & & & & \\
\hline
1.3 & BRISQUE quality gate \& normalisation & 07.04 & 17.04 & 8 &
  & \cellcolor{ganttblue!30} & \cellcolor{ganttblue!30} & & & & \\
\hline

% --- Section 2: Steganography ---
\rowcolor{ganttred!8}
\textbf{2} & \textbf{Steganography Implementation} & & & & & & & & & & \\
\hline
2.1 & LSB embedding pipeline ($k\!=\!1,2$) & 07.04 & 17.04 & 8 &
  & \cellcolor{ganttred!50} & \cellcolor{ganttred!50} & & & & \\
\hline
2.2 & DCT-QIM embedding pipeline & 07.04 & 17.04 & 8 &
  & \cellcolor{ganttred!50} & \cellcolor{ganttred!50} & & & & \\
\hline
2.3 & AES-256-CBC payload encryption & 14.04 & 17.04 & 4 &
  & & \cellcolor{ganttred!30} & & & & \\
\hline

% --- Section 3: Detection ---
\rowcolor{ganttgreen!8}
\textbf{3} & \textbf{Detection \& Analysis} & & & & & & & & & & \\
\hline
3.1 & RS Analysis + $\chi^2$ detector & 14.04 & 24.04 & 8 &
  & & \cellcolor{ganttgreen!50} & \cellcolor{ganttgreen!50} & & & \\
\hline
3.2 & SRM + FLD training & 14.04 & 01.05 & 14 &
  & & \cellcolor{ganttgreen!50} & \cellcolor{ganttgreen!50} & \cellcolor{ganttgreen!50} & & \\
\hline
3.3 & Image quality metrics (PSNR/SSIM/FSIM) & 21.04 & 01.05 & 8 &
  & & & \cellcolor{ganttamber!50} & \cellcolor{ganttamber!50} & & \\
\hline
3.4 & Encryption-effect experiments (RQ3) & 28.04 & 08.05 & 8 &
  & & & & \cellcolor{ganttpurple!50} & \cellcolor{ganttpurple!50} & \\
\hline
3.5 & Statistical analysis (ANOVA, Wilcoxon) & 28.04 & 08.05 & 8 &
  & & & & \cellcolor{ganttpurple!50} & \cellcolor{ganttpurple!50} & \\
\hline

% --- Section 4: Writing ---
\rowcolor{ganttgray!12}
\textbf{4} & \textbf{Writing \& Revision} & & & & & & & & & & \\
\hline
4.1 & Visualisations + report writing & 04.05 & 15.05 & 8 &
  & & & & & \cellcolor{ganttgray!50} & \cellcolor{ganttgray!50} \\
\hline
4.2 & Buffer / final revision & 11.05 & 15.05 & 5 &
  & & & & & & \cellcolor{ganttgray!30} \\
\hline

\end{tabularx}
}%

\vspace{6pt}
\noindent{\small\color{umgray}%
\textcolor{ganttblue!60}{$\blacksquare$}~Data\enspace
\textcolor{ganttred!60}{$\blacksquare$}~Steganography\enspace
\textcolor{ganttgreen!60}{$\blacksquare$}~Detection\enspace
\textcolor{ganttamber!60}{$\blacksquare$}~Evaluation\enspace
\textcolor{ganttpurple!60}{$\blacksquare$}~Analysis\enspace
\textcolor{ganttgray!60}{$\blacksquare$}~Writing}

\vspace{4pt}
\noindent{\small\textbf{Milestones:}
\textbf{M1}~(end Wk\,2): Dataset ready \quad
\textbf{M2}~(end Wk\,3): Embedding pipelines verified \quad
\textbf{M3}~(end Wk\,5): All experiments complete \quad
\textbf{M4}~(end Wk\,7): Report submitted}

% ------------------------------------------------------------------
% Phase 3: Completion (Project Period, 25 May -- 12 Jun 2026, 3 weeks)
% ------------------------------------------------------------------

\vspace{20pt}

\noindent\textbf{\large Phase 3: Completion} \hfill
\textit{Project Period: 25~May\,--\,12~June 2026 (3~weeks)}

\vspace{6pt}

{%
\setlength{\tabcolsep}{2pt}
\renewcommand{\arraystretch}{1.2}
\footnotesize
\noindent\begin{tabularx}{\textwidth}{
  |>{\centering\arraybackslash}p{0.8cm}
  |>{\raggedright\arraybackslash}p{4.6cm}
  |>{\centering\arraybackslash}p{1.2cm}
  |>{\centering\arraybackslash}p{1.2cm}
  |>{\centering\arraybackslash}p{0.8cm}
  |*{3}{>{\centering\arraybackslash}X|}
}
\hline
\rowcolor{umdark!10}
\textbf{WBS} & \textbf{Task} & \textbf{Start} & \textbf{End} & \textbf{Days} &
\textbf{Wk\,1} & \textbf{Wk\,2} & \textbf{Wk\,3} \\
\hline

1.1 & Complete remaining implementation & 25.05 & 05.06 & 10 &
  \cellcolor{ganttblue!50} & \cellcolor{ganttblue!50} & \\
\hline
1.2 & Verify results \& rerun experiments & 25.05 & 05.06 & 10 &
  \cellcolor{ganttgreen!50} & \cellcolor{ganttgreen!50} & \\
\hline
1.3 & Statistical verification \& effect sizes & 01.06 & 05.06 & 5 &
  & \cellcolor{ganttamber!50} & \\
\hline
2.1 & Presentation slides & 01.06 & 08.06 & 6 &
  & \cellcolor{ganttpurple!50} & \cellcolor{ganttpurple!50} \\
\hline
2.2 & Poster & 05.06 & 10.06 & 4 &
  & & \cellcolor{ganttred!50} \\
\hline
2.3 & Final paper write-up & 01.06 & 12.06 & 10 &
  & \cellcolor{ganttgray!50} & \cellcolor{ganttgray!50} \\
\hline
2.4 & Buffer / revision / submission & 10.06 & 12.06 & 3 &
  & & \cellcolor{ganttgray!30} \\
\hline

\end{tabularx}
}%

\vspace{6pt}
\noindent{\small\color{umgray}%
\textcolor{ganttblue!60}{$\blacksquare$}~Implementation\enspace
\textcolor{ganttgreen!60}{$\blacksquare$}~Verification\enspace
\textcolor{ganttamber!60}{$\blacksquare$}~Analysis\enspace
\textcolor{ganttpurple!60}{$\blacksquare$}~Slides\enspace
\textcolor{ganttred!60}{$\blacksquare$}~Poster\enspace
\textcolor{ganttgray!60}{$\blacksquare$}~Paper}

\vspace{4pt}
\noindent{\small\textbf{Milestones:}
\textbf{M5}~(end Wk\,1): Implementation finalised \quad
\textbf{M6}~(end Wk\,2): Results verified, slides ready \quad
\textbf{M7}~(end Wk\,3): All deliverables submitted}

\end{document}
