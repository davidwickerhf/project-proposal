===== PAGE 1 =====
Group Number: 02 
Group Members: Abdul Moiz Akbar, Malo Coquin, Daria Gjonbalaj, Nico Müller-Späth, 
Jimena
 
Narvaez
 
del
 
Cid,
 
David
 
Wicker,
 
Nikolas
 
Zouros
 
Umbrella topic: Applied Cryptography 
Proposal title: Image Steganography and Steganalysis 
 
1 Motivation and problem statement (500 words max) - Nick ........................................................ 1 2 Research questions (at least 3 concrete research questions) - Daria ............................................. 1 3 Chosen approaches (700 words max) - David & Jimena .............................................................. 2 4 Experiments (300 words max) - David ......................................................................................... 4 5 Prototype (100 words max) - Nico ................................................................................................ 4 7 Relation of proposal to courses in your curriculum (50 words max) - Nico ................................ 5 8 Planning (2 Gantt Charts in a readable format) - Abdul ............................................................... 5 9 Minimal passing requirements (50 words max) - Daria ............................................................... 6 10 References (no limit, but at least 10 references) - Abdul ........................................................... 7 
1 Motivation and problem statement (500 words max) - Nick
 
● We could open by framing image steganography as a core information-security topic and noting 
that
 
detectability
 
depends
 
on
 
carrier-image
 
statistics,
 
not
 
only
 
on
 
the
 
embedding
 
rule
 
(Petitcolas
 
et
 
al.,
 
1999;
 
Cheddad
 
et
 
al.,
 
2010;
 
Hussain
 
et
 
al.,
 
2018;
 
Fridrich
 
&
 
Kodovsky,
 
2012).
 ● It may help to state explicitly that most steganalysis pipelines are developed and evaluated on 
real
 
camera
 
photographs,
 
where
 
sensor
 
noise
 
and
 
compression
 
behavior
 
are
 
relatively
 
well
 
characterized
 
(Fridrich
 
&
 
Kodovsky,
 
2012).
 ● We can then introduce the shift in context: photorealistic synthetic images from modern 
generators
 
are
 
now
 
common
 
and
 
are
 
produced
 
through
 
fundamentally
 
different
 
generation
 
processes
 
(Rombach
 
et
 
al.,
 
2022;
 
Karras
 
et
 
al.,
 
2021).
 ● A useful bridge is to mention that these processes leave different statistical traces, so carrier 
origin
 
itself
 
may
 
influence
 
steganographic
 
detectability
 
(Wang
 
et
 
al.,
 
2020;
 
Corvi
 
et
 
al.,
 
2023).
 ● We can keep the central question explicit: do detectors validated on photographs remain equally 
effective
 
when
 
the
 
carrier
 
is
 
ML-generated?
 ● For impact framing, we can keep three dimensions:


===== PAGE 2 =====
● Security: if ML-generated carriers are harder to detect, attackers could evade existing detection 
by
 
switching
 
carrier
 
source
 
only.
 ● Scientific: the interaction between generative-model distributions and embedding perturbations is 
still
 
underexplored.
 ● Practical: as AI images spread in real communication channels, the steganographic attack 
surface
 
expands.
 ● It may be helpful to position De et al. as the closest precedent while clarifying that their setup 
differs
 
from
 
ours
 
in
 
method
 
and
 
evaluation
 
focus
 
(De
 
et
 
al.,
 
2022).
 
●
 
We
 
can
 
close
 
with
 
the
 
controlled
 
design
 
statement
 
to
 
show
 
rigor
 
and
 
feasibility:
 
a
 
2×2×3×2
 
factorial
 
setup
 
over
 
1,000
 
images,
 
using
 
CPU-feasible
 
tools.
 
Image Steganography plays an important role in today’s online security and privacy. It 
contributes
 
in
 
confidential
 
communication
 
and
 
supports
 
applications
 
and
 
websites
 
as
 
digital
 
copyright
 
protection.
 
However,
 
it
 
has
 
a
 
darker
 
side,
 
as
 
it
 
can
 
be
 
used
 
by
 
attackers
 
to
 
distribute
 
malware
 
in
 
a
 
network.
 
It
 
is
 
important
 
to
 
highlight
 
that
 
the
 
embedding
 
method
 
is
 
not
 
as
 
crucial
 
for
 
detectability
 
as
 
carrier-image
 
statistics
 
(e.g.
 
PSNR,
 
SNR,
 
SSIM).
 
As
 
far
 
as
 
today,
 
most
 
steganalysis
 
pipelines
 
are
 
focused
 
and
 
evaluated
 
on
 
real
 
world
 
images,
 
taken
 
by
 
humans
 
since
 
the
 
AI
 
image
 
generation
 
is
 
a
 
new
 
trend.
 
Diffusion
 
models,
 
which
 
are
 
responsible
 
for
 
image
 
generation,
 
are
 
creating
 
different
 
statistical
 
traces
 
than
 
the
 
ones
 
human
 
taken
 
pictures
 
do.
 
As
 
AI
 
image
 
generation
 
is
 
becoming
 
more
 
common,
 
it
 
is
 
worth
 
questioning
 
if
 
the
 
detectors
 
that
 
were
 
validated
 
on
 
photographs
 
are
 
still
 
effective
 
in
 
ML-generated
 
ones.
 
If
 
the
 
detectability
 
is
 
lower,
 
that
 
could
 
benefit
 
attackers
 
by
 
just
 
changing
 
the
 
carrier
 
source
 
and
 
could
 
lead
 
to
 
potential
 
risk
 
growth.
 
This
 
means
 
that
 
we
 
still
 
do
 
not
 
fully
 
comprehend
 
how
 
the
 
statistical
 
properties
 
of
 
AI
 
generated
 
images
 
are
 
being
 
altered
 
by
 
steganography.Our
 
work
 
will
 
examine
 
if
 
the
 
source
 
of
 
the
 
carrier
 
image
 
(real
 
human-taken
 
vs.
 
ML-generated)
 
affects
 
the
 
detectability
 
of
 
image
 
steganography
 
when
 
using
 
identical
 
embedding
 
methods
 
and
 
payload
 
sizes.
 
2 Research questions (at least 3 concrete research questions) 
1. Carrier Origin: Is there any effect from the origin of a carrier image (real vs 
AI-generated)
 
in
 
how
 
easily
 
hidden
 
data
 
can
 
be
 
detected?
 
 2. Payload: Does increasing the payload size widen the detectability gap between images of 
different
 
origin
 
carriers?
 3. Encryption: Does encrypting the payload before embedding make steganography easier 
or
 
harder
 
to
 
detect,
 
and
 
is
 
it
 
affected
 
by
 
the
 
carrier
 
origin?
 4. Embedding Method: Do different embedding methods (e.g., spatial-domain LSB vs. 
frequency-domain
 
DCT)
 
interact
 
differently
 
with
 
carrier
 
origin
 
in
 
terms
 
of
 
detectability?
 5. Image Quality: Is image quality visibly affected when applying different embedding 
methods
 
or
 
when
 
applying
 
a
 
greater/smaller
 
amount
 
of
 
hidden
 
data?


===== PAGE 3 =====
3 Chosen approaches (700 words max) - David & Jimena Datasets Real images ( 500 total). We will use as an image resource three different, diverse, and complete 
photographic
 
databases:
 
RAISE
 
(Dang-Nguyen
 
et
 
al.,
 
2015)
 
contributes
 
250
 
high-resolution
 
RAW
 
images
 
spanning
 
outdoor,
 
indoor,
 
portrait,
 
and
 
macro
 
scenes;
 
COCO
 
(Lin
 
et
 
al.,
 
2014)
 
contributes
 
150
 
images
 
from
 
its
 
validation
 
split;
 
and
 
Flickr30k
 
(Young
 
et
 
al.,
 
2014)
 
contributes
 
100
 
images.
 
All
 
images
 
are
 
normalized
 
to
 
a
 
512×512
 
px,
 
RGB,
 
8-bit,
 
lossless
 
PNG.
 
RAISE
 
is
 
preferred
 
as
 
the
 
primary
 
source
 
because
 
its
 
RAW
 
format
 
preserves
 
camera
 
sensor
 
noise
 
structure,
 
which
 
is
 
the
 
natural
 
image
 
statistics
 
that
 
steganalysis
 
exploits.
 ML-generated images ( 500 total). We generate two matched sets of 250 images each using 
Stable
 
Diffusion
 
v2.1
 
(Rombach
 
et
 
al.,
 
2022)
 
via
 
the
 
diffusers
 
library
 
on
 
Apple
 
MPS
 
and
 
StyleGAN3
 
(Karras
 
et
 
al.,
 
2021)
 
using
 
the
 
official
 
NVIDIA
 
PyTorch
 
implementation.
 
Prompts
 
for
 
SD
 
are
 
derived
 
directly
 
from
 
COCO/Flickr30k
 
captions
 
to
 
achieve
 
semantic
 
alignment
 
with
 
real
 
images.
 
A
 
BRISQUE
 
≤
 
50
 
optimal
 
threshold
 
is
 
applied
 
to
 
filter
 
high-quality
 
images.
 Both Stable Diffusion, which is focused on generating the image by denoising a 
generated
 
image
 
as
 
much
 
as
 
it
 
can,
 
and
 
StyleGAN3,
 
which
 
improves
 
a
 
generated
 
image
 
until
 
it
 
looks
 
realistic,
 
represent
 
the
 
dominant
 
architectures
 
used
 
in
 
image
 
generation
 
and
 
are
 
expected
 
to
 
impose
 
distinct
 
statistical
 
signatures
 
on
 
the
 
output.
 Embedding Methods We implement two canonical steganographic methods spanning the two principal domains: LSB substitution (spatial domain) replaces the k least significant bits of each pixel channel 
value
 
with
 
bits
 
of
 
a
 
secret
 
message,
 
using
 
a
 
PRNG-keyed
 
pixel
 
selection
 
mask.
 
We
 
test
 
k
 
=
 
1
 
(Low,
 
Medium
 
payload)
 
and
 
k
 
=
 
2
 
(High
 
payload).
 
Payloads
 
are
 
optionally
 
pre-encrypted
 
with
 
AES-256-CBC
 
before
 
embedding,
 
addressing
 
RQ4's
 
encryption
 
sub-question.
 DCT-based embedding (frequency domain) partitions each image channel into 
non-overlapping
 
8×8
 
blocks,
 
computes
 
the
 
2D
 
DCT,
 
and
 
embeds
 
bits
 
into
 
mid-frequency
 
coefficients
 
(zigzag
 
positions
 
10–54)
 
via
 
Quantization
 
Index
 
Modulation
 
(QIM;
 
Chen
 
&
 
Wornell,
 
2001):
 
C'_i = Δ · round(C_i / Δ) ± Δ/4 
 where the sign encodes the message bit. DCT embedding is chosen alongside LSB to test 
whether
 
frequency-domain
 
methods
 
are
 
more
 
sensitive
 
to
 
carrier
 
origin
 
(H3),
 
since
 
DCT
 
coefficients
 
reflect
 
the
 
generative
 
model's
 
learned
 
spectral
 
distribution
 
directly.
 Steganalysis Detectors


===== PAGE 4 =====
Our detector selection is deliberately scoped to classical signal processing and statistics, 
consistent
 
with
 
this
 
project's
 
cryptography/steganography
 
focus:
 
Detector Type Training Domain Time 
RS Analysis Statistical None Any ~2 s/img 
χ² attack Statistical None LSB <1 s/img 
SRM+FLD Classical ML Labeled LSB+DCT <30 min 
 RS Analysis (Fridrich et al., 2001) partitions an image into pixel groups and classifies each as 
Regular
 
or
 
Singular
 
by
 
a
 
smoothness
 
function;
 
LSB
 
embedding
 
shifts
 
the
 
R/S
 
ratio
 
predictably,
 
yielding
 
an
 
analytical
 
estimate
 
p̂
 
of
 
embedding
 
rate.
 
Since
 
it
 
requires
 
no
 
training,
 
any
 
detection
 
difference
 
between
 
real
 
and
 
ML-generated
 
carriers
 
is
 
attributable
 
solely
 
to
 
carrier
 
statistics
 
and
 
not
 
to
 
classifier
 
bias.
 SRM + Fisher Linear Discriminant (FLD) ensemble (Fridrich & Kodovský, 2012) extracts 
35,00
 
different
 
statistical
 
features
 
and
 
characteristics,
 
then
 
classifies
 
with
 
an
 
ensemble
 
of
 
FLD
 
classifiers.
 
It
 
handles
 
DCT
 
embedding
 
better
 
than
 
the
 
training-free
 
methods
 
and
 
its
 
hand-crafted
 
features
 
are
 
hypothesised
 
to
 
generalise
 
better
 
across
 
the
 
real/ML
 
boundary
 
than
 
learned
 
neural
 
network
 
representations.
 
Implemented
 
with
 
scikit-learn's
 
SGDClassifier;
 
3-fold
 
stratified
 
CV.
 The χ² attack (Westfeld & Pfitzmann, 1999) is applied as a supplementary check on LSB results. Validation Detection : We consider the ROC-AUC as the primary metric. 
Image
 
quality
:
 
PSNR
 
(>
 
40
 
dB
 
target),
 
SSIM
 
(>
 
0.95
 
target),
 
FSIM.
 
Statistics
:
 
Two-way
 
ANOVA
 
(carrier
 
×
 
method)
 
on
 
AUC
 
with
 
payload
 
as
 
covariate;
 
Wilcoxon
 
signed-rank
 
for
 
pairwise
 
comparisons;
 
Cohen's
 
d
 
effect
 
sizes;
 
Bonferroni
 
correction
 
(α_
adj
 
=
 
0.05/6
 
≈
 
0.0083)
 
across
 
six
 
hypotheses.
 
4 Experiments (300 words max) - David
 
Each research question maps to exactly one experiment; every experiment links back to its RQ. Exp. 1 (RQ1: Carrier Origin Effect). Apply RS Analysis and SRM+FLD to all 1,000 images 
embedded
 
at
 
all
 
payload
 
levels
 
and
 
methods.
 
Compute
 
AUC
 
per
 
carrier
 
type
 
(conditions
 
A,
 
B).
 
Compare
 
real
 
vs.
 
ML-generated
 
AUC
 
with
 
the
 
Wilcoxon
 
signed-rank
 
test
 
and
 
Cohen's
 
d;
 
apply
 
Bonferroni
 
correction.
 
A
 
significant
 
difference
 
(Bonferroni-corrected
 
p
 
<
 
0.0083)
 
with
 
|d|
 
>
 
0.2
 
confirms
 
H1.
 Exp. 2 (RQ2: Payload Sensitivity). From Exp. 1 results, plot AUC vs. payload level 
(Low/Medium/High)
 
separately
 
for
 
real
 
and
 
ML-generated
 
carriers,
 
with
 
separate
 
curves
 
per


===== PAGE 5 =====
embedding method. Test whether the real–ML AUC gap increases monotonically using 
Spearman's
 
ρ
 
on
 
the
 
difference
 
series;
 
test
 
the
 
carrier
 
×
 
payload
 
interaction
 
in
 
ANOVA.
 Exp. 3 (RQ3: Method Interaction). Run a 2×2 two-way ANOVA with factors carrier origin 
(real/ML)
 
and
 
embedding
 
method
 
(LSB/DCT)
 
on
 
SRM
 
AUC
 
scores.
 
A
 
significant
 
interaction
 
(F-test,
 
Bonferroni-corrected)
 
indicates
 
the
 
method's
 
detectability
 
gap
 
depends
 
on
 
carrier
 
origin,
 
confirming
 
H3.
 Exp. 4 (RQ4: Encryption Effect). For each carrier type and embedding method, compare AUC 
scores
 
between
 
the
 
plain-payload
 
and
 
AES-256-CBC-encrypted-payload
 
conditions.
 
AES
 
encryption
 
randomises
 
the
 
bit
 
pattern
 
of
 
the
 
message
 
before
 
embedding;
 
if
 
detector
 
AUC
 
drops
 
significantly
 
(Wilcoxon
 
signed-rank,
 
Bonferroni-corrected),
 
this
 
indicates
 
that
 
the
 
message
 
structure
 
contributes
 
to
 
detection
 
beyond
 
purely
 
carrier-level
 
embedding
 
distortion.
 
An
 
interaction
 
with
 
carrier
 
type
 
(real
 
vs.
 
ML)
 
would
 
suggest
 
that
 
generative
 
model
 
statistics
 
moderate
 
the
 
encryption
 
benefit. 
5 Prototype (100 words max) - Nico 
 
● We could keep the vertical/horizontal split since it is clear and practical. ● Vertical prototype: validate each module separately (LSB, DCT-QIM, RS, SRM+FLD) before 
full-scale
 
runs
 
(Fridrich
 
et
 
al.,
 
2001;
 
Chen
 
&
 
Wornell,
 
2001;
 
Fridrich
 
&
 
Kodovsky,
 
2012).
 ● Horizontal prototype: run the integrated pipeline on a small mixed subset (real + ML-generated) to 
validate
 
interfaces.
 ● Then scale to the full experiment once outputs and metrics are consistent. 
 
6 Related work (500 words max) - Abdul
 Image Steganography has been focused on embedding secret data into photographic images 
using
 
spatial
 
and
 
frequency
 
domain
 
techniques.
 
Classical
 
surveys
 
(Petitcolas
 
et
 
al.,
 
1999;
 
Cheddad
 
et
 
al.,
 
2010;
 
Hussain
 
et
 
al.,
 
2018)
 
describe
 
methods
 
such
 
as
 
LSB
 
substitution
 
and
 
frequency-domain
 
embedding.
 
In
 
particular,
 
LSB-based
 
techniques
 
modify
 
pixel
 
intensities
 
directly,
 
while
 
frequency-domain
 
approaches
 
such
 
as
 
DCT-based
 
Quantization
 
Index
 
Modulation
 
(QIM)
 
embed
 
information
 
in
 
transform
 
coefficients
 
(Chen
 
&
 
Wornell,
 
2001).
 
Our
 
work
 
adopts
 
these
 
established
 
post-hoc
 
embedding
 
strategies
 
rather
 
than
 
proposing
 
a
 
new
 
embedding
 
algorithm.
 
This
 
ensures
 
comparability
 
with
 
prior
 
steganalysis
 
literature
 
and
 
allows
 
us
 
to
 
isolate
 
our
 
work
 
interest
 
in
 
carrier
 
origin.


===== PAGE 6 =====
Rich statistical models remain as a strong baseline. Fridrich & Kodovský (2012) introduced 
Spatial
 
Rich
 
Models
 
(SRM),
 
extracting
 
high-dimensional
 
co-occurrences
 
that
 
capture
 
embedding
 
artifacts.
 
Earlier
 
statistical
 
attacks
 
such
 
as
 
RS
 
analysis
 
(Fridrich
 
et
 
al.,
 
2001)
 
and
 
the
 
χ²
 
attack
 
(Westfeld
 
&
 
Pfitzmann,
 
1999)
 
provide
 
analytical
 
detection
 
of
 
LSB-like
 
embedding.
 
More
 
recent
 
work
 
has
 
explored
 
deep
 
learning-based
 
steganalysis
 
(Luo
 
et
 
al.,
 
2024),
 
often
 
achieving
 
high
 
detection
 
accuracy
 
but
 
at
 
the
 
cost
 
of
 
large
 
computational
 
requirements
 
and
 
reduced
 
interpretability.
 
Our
 
approach
 
deliberately
 
uses
 
classical
 
SRM+FLD
 
and
 
RS
 
analysis
 
to
 
maintain
 
interpretability
 
and
 
CPU
 
feasibility,
 
aligning
 
with
 
the
 
cryptography-focused
 
scope
 
of
 
this
 
project.
 
Recent work in generative modelling has introduced a different approach: generative 
steganography.
 
Instead
 
of
 
modifying
 
a
 
fixed
 
carrier
 
image,
 
GAN
 
or
 
diffusion
 
based
 
models
 
are
 
trained
 
to
 
generate
 
stego-images
 
directly
 
from
 
a
 
secret
 
message
 
(Hu
 
et
 
al.,
 
2023;
 
Liu
 
et
 
al.,
 
2024).
 
Similarly,
 
coverless
 
steganography
 
(Duan
 
et
 
al.,
 
2020)
 
encodes
 
information
 
by
 
selecting
 
or
 
generating
 
content
 
rather
 
than
 
altering
 
pixel
 
values.
 
These
 
approaches
 
fundamentally
 
integrate
 
embedding
 
into
 
the
 
generation
 
process
 
itself.
 
Our
 
work
 
differs
 
from
 
generative
 
and
 
coverless
 
steganography
 
in
 
a
 
crucial
 
way:
 
we
 
treat
 
ML-generated
 
images
 
as
 
passive
 
carriers
 
and
 
apply
 
standardized
 
post-hoc
 
embedding
 
(LSB
 
and
 
DCT).
 
By
 
keeping
 
generation
 
and
 
embedding
 
conceptually
 
separate,
 
we
 
can
 
explicitly
 
test
 
whether
 
the
 
statistical
 
distribution
 
of
 
synthetic
 
images
 
affects
 
detectability
 
under
 
identical
 
embedding
 
conditions.
 
The closest related study is De et al. (2022), which uses AI-generated photorealistic images for 
steganographic
 
secret
 
sharing.
 
However,
 
their
 
work
 
does
 
not
 
perform
 
a
 
controlled
 
real-versus-ML
 
comparison
 
under
 
identical
 
embedding
 
pipelines,
 
nor
 
do
 
they
 
evaluate
 
detectability
 
using
 
classical
 
steganalysis
 
metrics
 
such
 
as
 
ROC-AUC.
 
Our
 
factorial
 
design
 
(carrier
 
origin
 
×
 
embedding
 
method
 
×
 
payload
 
size
 
×
 
encryption)
 
directly
 
measures
 
detectability
 
differences,
 
making
 
steganalysis
 
performance
 
the
 
primary
 
endpoint
 
rather
 
than
 
successful
 
message
 
reconstruction.
 
Cross-domain steganalysis usually studies differences between images from different cameras. 
However,
 
the
 
difference
 
between
 
real
 
photos
 
and
 
GAN-
 
or
 
diffusion-generated
 
images
 
is
 
much
 
larger.
 
Research
 
in
 
synthetic
 
image
 
forensics
 
shows
 
that
 
AI-generated
 
images
 
have
 
distinct
 
statistical
 
patterns,
 
which
 
may
 
affect
 
steganographic
 
detectability.
 
Our
 
work
 
connects
 
these
 
two
 
areas
 
by
 
testing
 
whether
 
carrier
 
origin
 
influences
 
detection
 
performance.
 
In summary, while prior work has studied embedding techniques, steganalysis models, 
generative
 
steganography,
 
and
 
synthetic
 
image
 
detection
 
separately,
 
our
 
contribution
 
lies
 
in
 
systematically
 
evaluating
 
how
 
the
 
origin
 
of
 
the
 
carrier
 
image
 
affects
 
steganographic
 
detectability
 
under
 
controlled
 
and
 
comparable
 
conditions.


===== PAGE 7 =====
● Generative steganography work often uses GANs or diffusion models as the embedding 
mechanism
 
itself,
 
where
 
content
 
is
 
generated
 
to
 
carry
 
messages
 
(Hu
 
et
 
al.,
 
2023;
 
Liu
 
et
 
al.,
 
2024).
 ● Coverless steganography similarly generates stego content directly, rather than modifying a fixed 
carrier
 
image
 
(Duan
 
et
 
al.,
 
2020).
 ● Our scope differs: we treat ML-generated images as passive carriers and apply standardized 
post-hoc
 
embedding
 
(LSB/DCT),
 
keeping
 
generation
 
and
 
embedding
 
conceptually
 
separate.
 ● The closest “AI-generated carrier” precedent is De et al., who show secret sharing with 
AI-generated
 
images
 
(De
 
et
 
al.,
 
2022).
 ● We can highlight three differences from De et al.: bespoke probabilistic embedding, no controlled 
real-vs-ML
 
side-by-side
 
design,
 
and
 
no
 
steganalysis
 
detectability
 
endpoint
 
(De
 
et
 
al.,
 
2022).
 ● Cross-domain steganalysis literature mainly addresses camera-to-camera shift; we examine a 
larger
 
domain
 
shift
 
from
 
camera-captured
 
to
 
model-synthesized
 
images
 
(Fridrich
 
&
 
Kodovsky,
 
2012).
 ● Deepfake/synthetic-image forensics provides evidence that synthetic images are statistically 
distinguishable
 
from
 
photographs,
 
supporting
 
our
 
hypothesis
 
that
 
carrier
 
origin
 
can
 
matter
 
(Wang
 
et
 
al.,
 
2020;
 
Corvi
 
et
 
al.,
 
2023).
 ● We can also acknowledge deep-learning steganalysis advances while justifying SRM+FLD for 
interpretability,
 
scope
 
alignment,
 
and
 
CPU
 
feasibility
 
(Luo
 
et
 
al.,
 
2024;
 
Fridrich
 
&
 
Kodovsky,
 
2012).
 
 
7 Relation of proposal to courses in your curriculum (50 
words
 
max)
 
-
 
Nico
 
This project connects to Computer Security through encryption. AI and Machine Learning is 
applied
 
for
 
classification,
 
data
 
splitting,
 
and
 
evaluation
 
metrics.
 
Software
 
Engineering
 
and
 
Architectures
 
ensures
 
a
 
modular
 
pipeline
 
design.
 
Statistics
 
is
 
needed
 
for
 
mathematically
 
grounded
 
evaluation
 
and
 
comparison
 
of
 
detection
 
performance
 
between
 
AI-generated
 
and
 
natural
 
images.
 
Note: I would like to explain it a bit more but 50 words is like nothing…. 
● Cryptography and steganography: spatial/frequency embedding, payload encryption, and 
detectability-oriented
 
reasoning
 
(Fridrich
 
et
 
al.,
 
2001;
 
Chen
 
&
 
Wornell,
 
2001).


===== PAGE 8 =====
● Machine learning: feature-based steganalysis through SRM and linear discriminant classification 
(Fridrich
 
&
 
Kodovsky,
 
2012).
 
8 Planning (2 Gantt Charts in a readable format) - Abdul


===== PAGE 9 =====
9 Minimal passing requirements (50 words max)
 
In terms of approaches, we believe we need to include at least one encryption algorithm and two 
embedding
 
ones
 
–
 
one
 
on
 
the
 
spatial
 
domain
 
and
 
one
 
on
 
the
 
frequency
 
domain.
 
And
 
from
 
our
 
five
 
research
 
questions,
 
we
 
believe
 
we
 
need
 
to
 
have
 
answered
 
at
 
least
 
RQ3
 
and
 
RQ4. 
10 References (no limit, but at least 10 references) - Abdul
 
Chen, B., & Wornell, G. W. (2001). Quantization index modulation: A class of provably good 
methods
 
for
 
digital
 
watermarking
 
and
 
information
 
embedding.
 
IEEE
 
Transactions
 
on
 
Information
 
Theory
,
 
47
(4),
 
1423–1443.
 Cheddad, A., Condell, J., Curran, K., & McKevitt, P. (2010). Digital image steganography: 
Survey
 
and
 
analysis
 
of
 
current
 
methods.
 
Signal
 
Processing
,
 
90
(3),
 
727–752.
 Corvi, R., Cozzolino, D., Zingarini, G., Poggi, G., Nagano, K., & Verdoliva, L. (2023). On the 
detection
 
of
 
synthetic
 
images
 
generated
 
by
 
diffusion
 
models.
 
In
 
Proceedings
 
of
 
the
 
IEEE
 
ICASSP
 
(pp.
 
1–5).
 Dang-Nguyen, D.-T., Pasquini, C., Conotter, V., & Boato, G. (2015). RAISE: A raw images 
dataset
 
for
 
digital
 
image
 
forensics.
 
In
 
Proceedings
 
of
 
the
 
ACM
 
Multimedia
 
Systems
 
Conference
 
(MMSys)
 
(pp.
 
219–224).
 De, A., Kinzel, W., & Kanter, I. (2022). Steganographic secret sharing via AI-generated 
photorealistic
 
images.
 
EURASIP
 
Journal
 
on
 
Wireless
 
Communications
 
and
 
Networking
,
 
Article
 
108.
 Duan, X., Jia, D., Li, B., Guo, D., Zhang, E., & Qin, C. (2020). Coverless steganography based 
on
 
generative
 
adversarial
 
network.
 
EURASIP
 
Journal
 
on
 
Image
 
and
 
Video
 
Processing
,
 
Article
 
46.
 Fridrich, J., & Kodovský, J. (2012). Rich models for steganalysis of digital images. IEEE 
Transactions
 
on
 
Information
 
Forensics
 
and
 
Security
,
 
7
(3),
 
868–882.
 Fridrich, J., Goljan, M., & Du, R. (2001). Detecting LSB steganography in color and grayscale 
images.
 
IEEE
 
Multimedia
,
 
8
(4),
 
22–28.
 Holub, V., Fridrich, J., & Denemark, T. (2014). Universal distortion function for steganography 
in
 
an
 
arbitrary
 
domain.
 
EURASIP
 
Journal
 
on
 
Information
 
Security
,
 
Article
 
1.
 Hu, P., et al. (2023). A coverless image steganography based on generative adversarial networks. 
Electronics
,
 
12
(5),
 
Article
 
1253.
 Hussain, M., Wahab, A. W. A., Idris, Y. I. B., Ho, A. T. S., & Jung, K. H. (2018). Image 
steganography
 
in
 
spatial
 
domain:
 
A
 
survey.
 
Signal
 
Processing:
 
Image
 
Communication
,
 
65
,
 
46–66.


===== PAGE 10 =====
Karras, T., Laine, S., Aittala, M., Hellsten, J., Lehtinen, J., & Aila, T. (2021). Alias-free 
generative
 
adversarial
 
networks.
 
In
 
Advances
 
in
 
Neural
 
Information
 
Processing
 
Systems
 
(NeurIPS)
 
(Vol.
 
34,
 
pp.
 
852–863).
 Lin, T.-Y., et al. (2014). Microsoft COCO: Common objects in context. In Proceedings of the 
European
 
Conference
 
on
 
Computer
 
Vision
 
(ECCV)
 
(LNCS
 
8693,
 
pp.
 
740–755).
 Liu, X., et al. (2024). Message-driven generative steganography using GAN. IEEE Transactions 
on
 
Dependable
 
and
 
Secure
 
Computing
.
 Luo, Y., et al. (2024). Deep learning for steganalysis of diverse data types: A review. 
Neurocomputing
,
 
Elsevier.
 Petitcolas, F. A. P., Anderson, R. J., & Kuhn, M. G. (1999). Information hiding: A survey. 
Proceedings
 
of
 
the
 
IEEE
,
 
87
(7),
 
1062–1078.
 Provos, N., & Honeyman, P. (2003). Hide and seek: An introduction to steganography. IEEE 
Security
 
&
 
Privacy
,
 
1
(3),
 
32–44.
 Rombach, R., Blattmann, A., Lorenz, D., Esser, P., & Ommer, B. (2022). High-resolution image 
synthesis
 
with
 
latent
 
diffusion
 
models.
 
In
 
Proceedings
 
of
 
the
 
IEEE/CVF
 
Conference
 
on
 
Computer
 
Vision
 
and
 
Pattern
 
Recognition
 
(CVPR)
 
(pp.
 
10684–10695).
 Wang, S.-Y., Wang, O., Zhang, R., Owens, A., & Efros, A. A. (2020). CNN-generated images are 
surprisingly
 
easy
 
to
 
spot…
 
for
 
now.
 
In
 
Proceedings
 
of
 
the
 
IEEE/CVF
 
Conference
 
on
 
Computer
 
Vision
 
and
 
Pattern
 
Recognition
 
(CVPR)
 
(pp.
 
8695–8704).
 Westfeld, A., & Pfitzmann, A. (1999). Attacks on steganographic systems. In Proceedings of the 
3rd
 
International
 
Workshop
 
on
 
Information
 
Hiding
 
(LNCS
 
1768,
 
pp.
 
61–76).
 Young, P., Lai, A., Hodosh, M., & Hockenmaier, J. (2014). From image descriptions to visual 
denotations.
 
Transactions
 
of
 
the
 
Association
 
for
 
Computational
 
Linguistics
,
 
2
,
 
67–78.
 RAISE - the Raw Images Dataset . (n.d.). https://loki.disi.unitn.it/RAISE/
